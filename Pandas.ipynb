{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas and working with structured (survey) data\n",
    "\n",
    "This notebook will introduce you to the Python Data Analysis Library, better known as Pandas (https://pandas.pydata.org/). Pandas is a very powerful package that provides similar functionality to R. At the core of Pandas is the **'DataFrame'**, which is a two-dimensional tabular data structure. Think of it as a spreadsheet. Columns have names that allow you to reference different columns depending on the analysis or data manipulations you are doing. In most cases you apply operations to data in all rows. \n",
    "\n",
    "In many sciences, the most common way to get data into a dataframe is through the Comma-Separated Variable (CSV) file. If you have an Excel spreadsheet you can save it as a CSV file by going to File -> Save As -> Select CSV under \"Save as type.\"\n",
    "\n",
    "**Note** Fortunately Pandas has fantastic documentation. Take a look at their Getting started page with a series of tutorials:\n",
    "https://pandas.pydata.org/docs/getting_started/index.html\n",
    "\n",
    "In this notebook we setup a 3 stage pipeline:\n",
    "1. open and read data\n",
    "2. clean up data\n",
    "3. analyze data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. A small survey\n",
    "I created a small survey using SurveyMonkey to create a straightforward dataset that we can work on. Take a look at the questions\n",
    "\n",
    "https://www.surveymonkey.com/r/MHKYM6D\n",
    "    \n",
    " * Q1: Are you left handed?\n",
    " * Q2: Do colleges and universities give too much attention to its sports programs, too little attention, or about the right amount of attention?\n",
    " * Q3: What is your favorite ice cream?\n",
    " * Q4: Describe the weather today.\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Open and read data into a DataFrame\n",
    "\n",
    "We will import the pandas module and rename it to 'pd' to save on typing. This is the way. (Of the lazy programmer)\n",
    "\n",
    "Next, we will use the read_csv function to read in our small survey data in the following file: \"smallsurvey.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "survey = pd.read_csv(\"smallsurvey.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will visualize what our smallsurvey data looks like. You will see we 'received' 13 responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Cleaning, Filtering, and Wrangling\n",
    "This second step will show basic Pandas operations for cleaning and filtering data. This is sometimes called 'data wrangling' or 'data munging.' If we quickly scan the data, we can see that it does not have too many issues, but there are always different ways to work with data. We will cover a few."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a single column and store it in 'lefty'\n",
    "# Notice the double square brackets. We are passing in a list that includes a single column\n",
    "# This does something rather important. It will give us back a dataframe.\n",
    "# If you remove one set of square brackets --i.e., survey[\"Q1\"] -- then the results will give you something called a series.\n",
    "\n",
    "left_column = survey[[\"Q1\"]]\n",
    "\n",
    "left_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select two columns\n",
    "# Notice the double square brackets. We are passing in a list of column names!\n",
    "\n",
    "left_ic_columns = survey[[\"Q1\", \"Q3\"]]\n",
    "\n",
    "# Show left + ice cream\n",
    "left_ic_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only respondents who answered 'Yes' to being left handed.\n",
    "\n",
    "survey[\"Q1\"] == \"Yes\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wait?! Pandas messed up AND I lost my nicely formatted boxes. \n",
    "\n",
    "First, Pandas did not mess up. No one answered\n",
    "\n",
    "Yes\n",
    "\n",
    "They answered\n",
    "\n",
    "\"Yes\"\n",
    "\n",
    "Second, the data is not formatted because Pandas is not returning a dataframe. Rather it is giving you the results of your filter (cases where individuals answered 'Yes' to Q1). To get these responses back into our dataframe we need to do something rather strange."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only respondents who answered 'Yes' to being left handed.\n",
    "# To get to \"Yes\" we have to use an escape character '\\' and add some quotes.\n",
    "# This is common in text analytics so this example shows you how to do it.\n",
    "\n",
    "survey[\"Q1\"] == \"\\\"Yes\\\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, select only respondents who answered 'yes' to being left handed\n",
    "# AND put it back into a dataframe. (Notice the nicely formatted data)\n",
    "\n",
    "survey[survey[\"Q1\"] == \"\\\"Yes\\\"\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Your turn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's get all the vanilla ice cream lovers.\n",
    "\n",
    "# Write a line of code that creates a dataframe where respondents answered \"Vanilla\" for Q3.\n",
    "\n",
    "# Hint: you should get responses from 0, 6, 7, 9, and 13."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Wait!** What about respondent #2?  They answered ' vanilla' but not \"Vanilla\"\n",
    "\n",
    "This is the reason why data wrangling can take up a significant amount of time. Just because the computer can analyze the data, doesn't mean that it is doing it correctly. It is essential that you verify the results.\n",
    "\n",
    "So now we will focus on cleaning data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we will fix the \" vanilla\" response.\n",
    "# We will use the replace function using the 'easy way'\n",
    "\n",
    "survey.replace(\"\\\" vanilla\\\"\", \"\\\"Vanilla\\\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's double check our survey.\n",
    "survey"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wait! Respondent #2 did not change? That is because we did not save the result as survey. Let's try that again.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the replaced survey as clean_survey.\n",
    "# IMPORTANT! This allows us to separate the clean version from the 'raw data'\n",
    "clean_survey = survey.replace(\"\\\" vanilla\\\"\", \"\\\"Vanilla\\\"\")\n",
    "\n",
    "# Double check our work\n",
    "clean_survey"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Your turn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's clean up the cookie dough entry.\n",
    "# Write a line of code that removed the \"all the way\" phrase from respondent #4\n",
    "# Remember to use the clean_survey dataframe and not the original survey\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Removing quotes\n",
    "\n",
    "The quotes in the data are not great to work with. So let's clean them up.\n",
    "\n",
    "We will use the replace function again. And remove them one column at a time, because it is a bit easier and straightforward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_survey[\"Q1\"] = clean_survey[\"Q1\"].str.replace('\"', '')\n",
    "clean_survey[\"Q2\"] = clean_survey[\"Q2\"].str.replace('\"', '')\n",
    "clean_survey[\"Q3\"] = clean_survey[\"Q3\"].str.replace('\"', '')\n",
    "clean_survey[\"Q4\"] = clean_survey[\"Q4\"].str.replace('\"', '')\n",
    "\n",
    "# Check it out\n",
    "clean_survey"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to change the likert scale responses from \"1\" to 1 (an integer). This will allow us to manipulate them as numbers rather than strings of characters.\n",
    "\n",
    "See a nice walkthrough here: https://datatofish.com/string-to-integer-dataframe/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the to_numeric to convert all numbers for Q2 to numbers\n",
    "\n",
    "clean_survey['Q2'] = pd.to_numeric(clean_survey['Q2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding data.\n",
    "\n",
    "Sometimes you want to add another column of data. There are a variety of ways to do this in Pandas. Here is one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a column called X1 with a list of values\n",
    "clean_survey[\"X1\"] = [1, 1, 2, 1, 4, 2, 2 , 1, 3, 1, 2, 1, 3, 1]\n",
    "\n",
    "# Check it out\n",
    "clean_survey"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Analysis\n",
    "\n",
    "Now that we have a nice clean_survey dataframe. We can begin data analysis!\n",
    "Oftentimes this will be where you spend the least amount of time.\n",
    "This is because it takes a while to clean datasets and it takes a while to get visualizations 'just right.'\n",
    "Analysis tends to be quick to program.\n",
    "We will cover some of the basics and I will show you some additional resources.\n",
    "You can find other courses, workshops, and resources to cover statistics in greater depth."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descriptive statistics\n",
    "Note: I know that we only have 13 responses. We wanted something that is easy to manage. These functions will apply equally well with 13, 130, 1300, or even 1.3 million responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe function provides the most basic\n",
    "clean_survey[\"Q2\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Individual values if you want them\n",
    "\n",
    "print(\"mean\",clean_survey[\"Q2\"].mean())\n",
    "print(\"min\",clean_survey[\"Q2\"].min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sort data\n",
    "\n",
    "Here we can sort data based on the value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the values using Q2 values in decending order.\n",
    "\n",
    "# You try it: Try to change the order to ascending order.\n",
    "\n",
    "clean_survey.sort_values(by=\"Q2\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group data\n",
    "\n",
    "The groupby function is powerful, because we can apply statistical operations on groups (such as those people who are left versus right handed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First select two columns\n",
    "two = clean_survey[[\"Q1\",\"Q2\"]]\n",
    "\n",
    "# Now group respondents based on answer to Q1 and calculate the mean\n",
    "two.groupby(\"Q1\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "two[\"Q2\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now group respondents based on answer to Q1 and apply all descriptive statistics\n",
    "two.groupby(\"Q1\").describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation / COV\n",
    "\n",
    "We can calculate the correlation and covariance like so.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the covariance between Q1 and X1\n",
    "print(clean_survey[\"Q2\"].cov(clean_survey[\"X1\"]))\n",
    "\n",
    "# Just run it across all numerical columns\n",
    "clean_survey.cov()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You try it\n",
    "\n",
    "Now use the 'corr' function to print the correlation between Q1 and X1 and all the numerical columns.\n",
    "\n",
    "For another example look here: https://www.tutorialspoint.com/python_pandas/python_pandas_statistical_functions.htm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your correlation print statement between Q1/X1 here\n",
    "\n",
    "# Run correlation across all numerical columns here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scipy Statistics\n",
    "\n",
    "Now we get to the point where we want to break out of the limitations of Pandas and introduce other statistical packages. One popular stats package is Scipy.\n",
    "Scipy applies its functions to numpy arrays rather than dataframes. So we have to transform our data.\n",
    "\n",
    "Here is a list of statistical functions available to you:\n",
    "https://docs.scipy.org/doc/scipy/reference/stats.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the column Q2 and turn it to a numpy array\n",
    "np_q2 = clean_survey[\"Q2\"].to_numpy()\n",
    "\n",
    "# Check it out (notice the array at the beginning)\n",
    "np_q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import numpy and scipy/stats packages\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Calculate the trimmed mean\n",
    "print(\"Trimmed mean\",stats.tmean(np_q2))\n",
    "\n",
    "# Calculate the Bayesian confidence intervals for mean, var, and std.\n",
    "print(\"Bayes conf intervals\",stats.bayes_mvs(np_q2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we will try a pearson correlation\n",
    "\n",
    "# First get the x1 column to a numpy array\n",
    "np_x1 = clean_survey[\"X1\"].to_numpy()\n",
    "\n",
    "stats.pearsonr(np_q2, np_x1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text search (basics)\n",
    "\n",
    "Now we are going to pivot and focus our attention on Q4. How do we handle free form text?\n",
    "\n",
    "One basic way to identify whether entries contain certain words such as clouds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we will use the str.contains function\n",
    "# See here for more information: https://pandas.pydata.org/docs/reference/api/pandas.Series.str.contains.html\n",
    "clean_survey[\"Q4\"].str.contains('cloud')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can filter based on those entries that contains the word cloud\n",
    "\n",
    "clean_survey[clean_survey[\"Q4\"].str.contains('cloud')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also group by those that contain these words and apply statistics\n",
    "\n",
    "clean_survey.groupby(clean_survey[\"Q4\"].str.contains('cloud')).describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation\n",
    "\n",
    "By now you probably have noticed that writing Python code for the Pandas package can be tricky. It can be confusing where to put parentheses, brackets, periods, etc. What it takes is practice, practice practice. It also takes a search engine. Honestly, the way that I program is by looking up examples and following them until I get the right result. Some of these operations I have memorized and know exactly how they work, because I work with them often. Other operations I need to look up. It is important to know that just because it looks difficult doesn't mean that with a few searches you cannot solve the problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. You try!\n",
    "\n",
    "Now it is your turn.\n",
    "\n",
    "You will start working on your own pipeline. If you want to work on your own data, then please do so! If you are looking for other datasets, then you can also use seaborn's sample data.\n",
    "\n",
    "Here is a list: \n",
    " 'anagrams',\n",
    " 'anscombe',\n",
    " 'attention',\n",
    " 'brain_networks',\n",
    " 'car_crashes',\n",
    " 'diamonds',\n",
    " 'dots',\n",
    " 'exercise',\n",
    " 'flights',\n",
    " 'fmri',\n",
    " 'gammas',\n",
    " 'geyser',\n",
    " 'iris',\n",
    " 'mpg',\n",
    " 'penguins',\n",
    " 'planets',\n",
    " 'tips',\n",
    " 'titanic'\n",
    "\n",
    "Visit their webpage to see what each dataset looks like: https://github.com/mwaskom/seaborn-data\n",
    " * titanic has demographic data\n",
    " * flights has temporal data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is how you can get the titanic dataset (replace the name with another one if you wish)\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the titanic dataset and save it as a dataframe called tsurvey\n",
    "tsurvey = sns.load_dataset('titanic')\n",
    "\n",
    "# Check it out\n",
    "tsurvey"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Click on the link below to open the <a href=\"MyPipeline.ipynb\">MyPipeline.ipynb</a> and start creating your own pipeline. Currently only work on the first 3 stages. You will learn more about visualizations next.\n",
    "\n",
    "<a style=\"background:blue;padding:10px;color:white;font-weight:bold;\" href=\"MyPipeline.ipynb\">MyPipeline.ipynb</a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
